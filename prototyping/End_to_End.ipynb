{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data_root': '/home/data',\n",
      " 'deepmatch': '/home/deepmatching_1.2.2_c++/deepmatching-static'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 15)\n",
      "Found model /home/data/reid_models/stacknet64x64_84_BOTH.h5! :)\n",
      "Dt (3105, 6)\n",
      "total frames in video: 600\n",
      "Dt_new (557, 6)\n",
      "break\n",
      "edges for detection:  0  out of  557\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-d34e2f158e46>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m gg = GraphGenerator(root, video, Dt, dmax, W, video_name=video_name,\n\u001b[1;32m     45\u001b[0m                     \u001b[0mDM_object\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreid_object\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m                     is_memorized_reid=True)\n\u001b[0m",
      "\u001b[0;32m/home/cabbage/cabbage/MultiplePeopleTracking.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, video, detections, dmax, W, d, video_name, DM_object, reid_object, is_memorized_reid)\u001b[0m\n\u001b[1;32m     83\u001b[0m                             \u001b[0mconf1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m                             \u001b[0mconf2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m                             i1=i1, i2=i2)\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                     \u001b[0mcost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdelta\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m@\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cabbage/cabbage/features/GenerateFeatureVector.py\u001b[0m in \u001b[0;36mget_pairwise_vector\u001b[0;34m(self, video_name, I1, I2, frame1, frame2, bb1, bb2, conf1, conf2, i1, i2)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mst_cost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbb1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbb2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0mdm_cost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculate_cost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbb1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbb2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0mreid_cost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstacknet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mmin_conf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mconf2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cabbage/cabbage/features/deepmatching.py\u001b[0m in \u001b[0;36mcalculate_cost\u001b[0;34m(self, video_name, frame1, bb1, frame2, bb2)\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0mq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mis_same_frame\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m                 \u001b[0minside_one\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maabb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_inside\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbb1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m                 \u001b[0minside_two\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maabb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_inside\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbb2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "Settings = json.load(open('settings.txt'))\n",
    "pprint(Settings)\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from cabbage.regression.Regression import get_W_mot16_02_dmax100\n",
    "from cabbage.MultiplePeopleTracking import GraphGenerator\n",
    "from cabbage.features.deepmatching import ReadOnlyDeepMatching\n",
    "from cabbage.features.ReId import StoredReId\n",
    "from experiments import MOT16_Experiments\n",
    "from cabbage.data.video import VideoData\n",
    "\n",
    "root = Settings['data_root']\n",
    "\n",
    "mot16 = MOT16_Experiments(root)\n",
    "video_name = 'MOT16-02'\n",
    "video = mot16.mot16_02_X\n",
    "dmax = 100\n",
    "\n",
    "W = get_W_mot16_02_dmax100(root)\n",
    "print(W.shape)\n",
    "\n",
    "\n",
    "# set the correct DM's first!\n",
    "dm = ReadOnlyDeepMatching(root, 100)  # deep matches are set-up for 100 frames\n",
    "\n",
    "reid = StoredReId(root, dmax)\n",
    "reid.set_mot16_02_dmax100_true_predictions3105()\n",
    "\n",
    "\n",
    "Dt = mot16.mot16_02_true_detections_no_pid\n",
    "print(\"Dt\", Dt.shape)\n",
    "\n",
    "vd = VideoData(Dt)\n",
    "print('total frames in video:', vd.last_frame)\n",
    "Dt = vd.get_n_first_frames(150)\n",
    "print(\"Dt_new\", Dt.shape)\n",
    "\n",
    "gg = GraphGenerator(root, video, Dt, dmax, W, video_name=video_name,\n",
    "                    DM_object=dm, reid_object=reid, \n",
    "                    is_memorized_reid=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
