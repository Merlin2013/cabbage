{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MOT16: A Benchmark for Multi-Object Tracking\n",
    "\n",
    "Original paper: https://arxiv.org/pdf/1603.00831.pdf\n",
    "\n",
    "## Annotation Rules\n",
    "\n",
    "* **Targets**: All upgright people including\n",
    "    * walking, standing, running pedestrains\n",
    "    * cyclists, skaters\n",
    "    \n",
    "    \n",
    "* **Distractors**: Static people or representations\n",
    "    * people not int upgright position (sitting, lying down)\n",
    "    * reflections, drawings or photographs of people\n",
    "    * human-like objects like dolls, manneqins\n",
    "\n",
    "\n",
    "* **Others**: Moving vehicles and occluders\n",
    "    * Cars, bikes, motorbikes\n",
    "    * Pillars trees, building\n",
    "    \n",
    "### Y-detection \n",
    "\n",
    "| Position  | Name | Description |\n",
    "| ------------- | ------------- | ---------- |\n",
    "| 0  | Frame number  | Indicates at which frame the object is present  |\n",
    "| 2  | Bounding box left  | Coors of top-left corner of pedestrian bb |\n",
    "| 3  | Bounding box top  | Coors of top-left corner of pedestrian bb |\n",
    "| 4  | Bounding box width  | Coors of top-left corner of pedestrian bb |\n",
    "| 5  | Bounding box height  | Coors of top-left corner of pedestrian bb|\n",
    "| 6  | Confidence score | Indicates how confident the detector is that this instance is a pedestrian |\n",
    "\n",
    "Positions that are not described yield no function and can be ignored\n",
    "\n",
    "### Y-ground-truth\n",
    "\n",
    "| Position  | Name | Description |\n",
    "| ------------- | ------------- | ---------- |\n",
    "| 0  | Frame number  | Indicates at which frame the object is present  |\n",
    "| 1  | Identity number | Each pedestrian trjaectory is identified by a unique ID |\n",
    "| 2  | Bounding box left  | Coors of top-left corner of pedestrian bb |\n",
    "| 3  | Bounding box top  | Coors of top-left corner of pedestrian bb |\n",
    "| 4  | Bounding box width  | Coors of top-left corner of pedestrian bb |\n",
    "| 5  | Bounding box height  | Coors of top-left corner of pedestrian bb|\n",
    "| 6  | Confidence score | Flag wheather the entry is to be considered (1) or ignored (0) |\n",
    "| 7  | Class | Indicates the type of object annotated\n",
    "| 8  | Visibility | Visibility ratio, [0, 1], that says how much of that object is visible |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "could not find folder /home/julian/Data/pak_test1/MOT16...\n",
      "could not find file /home/julian/Data/pak_test1/MOT16.zip\n",
      "download from https://motchallenge.net/data/MOT16.zip\n",
      "https://motchallenge.net/data/MOT16.zip downloaded..\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0,'../')\n",
    "from pak import datasets\n",
    "from pak import utils\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "root = '/home/julian/Data/pak_test1'\n",
    "\n",
    "frame = 1\n",
    "resize = 0.5\n",
    "\n",
    "mot16 = datasets.MOT16(root, resize=resize)\n",
    "\n",
    "# the training set contains both detection as well as ground-truth data\n",
    "# while the test set only contains detection data.\n",
    "X, Y_det, Y_gt = mot16.get_train(\"MOT16-02\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "A = X[0:10]\n",
    "\n",
    "def get_visible_pedestrains(frame):\n",
    "    Y_gt_frame1 = utils.extract_eq(Y_gt, col=0, value=frame)\n",
    "    Y_gt_frame1 = utils.extract_eq(Y_gt_frame1, col=7, value=1)\n",
    "    Y_gt_frame1 = utils.extract_eq(Y_gt_frame1, col=8, value=1)\n",
    "    return Y_gt_frame1\n",
    "\n",
    "frame = 120\n",
    "\n",
    "import numpy as np\n",
    "from math import sqrt\n",
    "\n",
    "D = []\n",
    "for i in range(10):\n",
    "    D.append(get_visible_pedestrains(i+1))\n",
    "\n",
    "D = np.concatenate(D).astype('int64')\n",
    "\n",
    "\n",
    "def calculate_cost(one, two):\n",
    "    f1, pid1, x1, y1, bb_w1, bb_h1, _, _, _ = one\n",
    "    f2, pid2, x2, y2, bb_w2, bb_h2, _, _, _ = two\n",
    "    \n",
    "    h = (bb_h1 + bb_h2) / 2.0\n",
    "    f_st =  sqrt((x1 - x2)**2 + (y1 - y2)**2) / h\n",
    "    return f_st\n",
    "        \n",
    "\n",
    "def calculate_adj_list(Table, dst_theta=3):\n",
    "    n, _ = Table.shape\n",
    "    \n",
    "    edges = []\n",
    "    lifted_edges = []\n",
    "    \n",
    "    for i, entry in enumerate(Table):\n",
    "        f, pid, bb_left, bb_right, bb_w, bb_h, _, _, _ = entry\n",
    "        \n",
    "        for j in range(i+1, n):\n",
    "            f_o, pid_o, bb_left_o, bb_right_o, bb_w_o, bb_h_o, _, _, _ = Table[j]\n",
    "            \n",
    "            cost = calculate_cost(entry, Table[j])\n",
    "            print('cost:', cost)\n",
    "            \n",
    "            if abs(f_o - f) > dst_theta:\n",
    "                # lifted edge\n",
    "                pass\n",
    "            else:\n",
    "                # normal edge\n",
    "                pass\n",
    "                \n",
    "\n",
    "print(D.shape)\n",
    "calculate_adj_list(D)\n",
    "#print(D)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
