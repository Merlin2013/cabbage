{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MOT16: A Benchmark for Multi-Object Tracking\n",
    "\n",
    "Original paper: https://arxiv.org/pdf/1603.00831.pdf\n",
    "\n",
    "## Annotation Rules\n",
    "\n",
    "* **Targets**: All upgright people including\n",
    "    * walking, standing, running pedestrains\n",
    "    * cyclists, skaters\n",
    "    \n",
    "    \n",
    "* **Distractors**: Static people or representations\n",
    "    * people not int upgright position (sitting, lying down)\n",
    "    * reflections, drawings or photographs of people\n",
    "    * human-like objects like dolls, manneqins\n",
    "\n",
    "\n",
    "* **Others**: Moving vehicles and occluders\n",
    "    * Cars, bikes, motorbikes\n",
    "    * Pillars trees, building\n",
    "    \n",
    "### Y-detection \n",
    "\n",
    "| Position  | Name | Description |\n",
    "| ------------- | ------------- | ---------- |\n",
    "| 0  | Frame number  | Indicates at which frame the object is present  |\n",
    "| 2  | Bounding box left  | Coors of top-left corner of pedestrian bb |\n",
    "| 3  | Bounding box top  | Coors of top-left corner of pedestrian bb |\n",
    "| 4  | Bounding box width  | Coors of top-left corner of pedestrian bb |\n",
    "| 5  | Bounding box height  | Coors of top-left corner of pedestrian bb|\n",
    "| 6  | Confidence score | Indicates how confident the detector is that this instance is a pedestrian |\n",
    "\n",
    "Positions that are not described yield no function and can be ignored\n",
    "\n",
    "### Y-ground-truth\n",
    "\n",
    "| Position  | Name | Description |\n",
    "| ------------- | ------------- | ---------- |\n",
    "| 0  | Frame number  | Indicates at which frame the object is present  |\n",
    "| 1  | Identity number | Each pedestrian trjaectory is identified by a unique ID |\n",
    "| 2  | Bounding box left  | Coors of top-left corner of pedestrian bb |\n",
    "| 3  | Bounding box top  | Coors of top-left corner of pedestrian bb |\n",
    "| 4  | Bounding box width  | Coors of top-left corner of pedestrian bb |\n",
    "| 5  | Bounding box height  | Coors of top-left corner of pedestrian bb|\n",
    "| 6  | Confidence score | Flag wheather the entry is to be considered (1) or ignored (0) |\n",
    "| 7  | Class | Indicates the type of object annotated\n",
    "| 8  | Visibility | Visibility ratio, [0, 1], that says how much of that object is visible |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data_root': '/Users/basheq/Desktop/RGBD_Lab/Data',\n",
      " 'deepmatch': '/Users/basheq/Desktop/RGBD_Lab/deepmatching_1.2.2_c++/deepmatching'}\n",
      "/Users/basheq/Desktop/RGBD_Lab/Data/MOT16 found :)\n",
      "MOT16: load memmapped file /Users/basheq/Desktop/RGBD_Lab/Data/MOT16/train/MOT16-02/data.memmap\n",
      "MOT16 X loaded\n",
      "MOT16 Y_det loaded\n",
      "MOT16 Y_gt loaded\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pprint import pprint\n",
    "Settings = json.load(open('settings.txt'))\n",
    "pprint(Settings)\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0,'../')\n",
    "from pak.datasets.MOT import MOT16\n",
    "from pak import utils\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "root = Settings['data_root']\n",
    "\n",
    "#frame = 1\n",
    "#resize = 0.5\n",
    "\n",
    "mot16 = MOT16(root)\n",
    "\n",
    "# the training set contains both detection as well as ground-truth data\n",
    "# while the test set only contains detection data.\n",
    "X, Y_det, Y_gt = mot16.get_train(\"MOT16-02\", memmapped=True)\n",
    "video_name = \"MOT16-02\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(579, 9)\n"
     ]
    }
   ],
   "source": [
    "def get_visible_pedestrains(frame):\n",
    "    Y_gt_frame1 = utils.extract_eq(Y_gt, col=0, value=frame)\n",
    "    Y_gt_frame1 = utils.extract_eq(Y_gt_frame1, col=7, value=1)\n",
    "    Y_gt_frame1 = utils.extract_eq(Y_gt_frame1, col=8, value=1)\n",
    "    return Y_gt_frame1\n",
    "\n",
    "import numpy as np\n",
    "from math import sqrt\n",
    "\n",
    "nbr_frames = 100\n",
    "X_ = X[0:nbr_frames]\n",
    "\n",
    "D = []\n",
    "for i in range(nbr_frames):\n",
    "    D.append(get_visible_pedestrains(i+1))\n",
    "\n",
    "D = np.concatenate(D).astype('float32')\n",
    "print (D.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found model /Users/basheq/Desktop/RGBD_Lab/Data/reid_models/stacknet64x64_84acc.h5! :)\n"
     ]
    }
   ],
   "source": [
    "from cabbage.features.GenerateFeatureVector import pairwise_features\n",
    "from cabbage.features.deepmatching import ReadOnlyDeepMatching\n",
    "from cabbage.features.ReId import StackNet64x64\n",
    "from cabbage.regression.Regression import ReadOnlyRegression\n",
    "\n",
    "regression = ReadOnlyRegression(root, 'MOT16-11', 100)\n",
    "W = regression.get_weights()\n",
    "print(W.shape)\n",
    "\n",
    "\n",
    "delta_max = 15\n",
    "\n",
    "dm = ReadOnlyDeepMatching(root, 100)\n",
    "reid = StackNet64x64(root)\n",
    "\n",
    "gen = pairwise_features(\n",
    "            root,None,DM_object=dm, reid_object=reid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def calculate_cost(one, two):\n",
    "    f1, pid1, x1, y1, w1, h1, _, _, _ = one\n",
    "    f2, pid2, x2, y2, w2, h2, _, _, _ = two\n",
    "    \n",
    "    I1 = X_[int(f1-1)]\n",
    "    I2 = X_[int(f2-1)]\n",
    "    vec = gen.get_pairwise_vector(\n",
    "                            video_name ,\n",
    "                            I1, I2,\n",
    "                            f1,f2,\n",
    "                            (x1, y1, w1, h1),\n",
    "                            (x2, y2, w2, h2),\n",
    "                            3,3)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    ce = - np.log((1- np.exp(-f_st))/np.exp(-f_st))\n",
    "    \n",
    "    return ce\n",
    "        \n",
    "\n",
    "def calculate_adj_list(Table, dst_theta=3):\n",
    "    n, _ = Table.shape\n",
    "    \n",
    "    edges = []\n",
    "    lifted_edges = []\n",
    "    \n",
    "    ALL_EDGES = []\n",
    "    \n",
    "    for i, entry in enumerate(Table):\n",
    "        f, pid, bb_left, bb_right, bb_w, bb_h, _, _, _ = entry\n",
    "        \n",
    "        for j in range(i+1, n):\n",
    "            f_o, pid_o, bb_left_o, bb_right_o, bb_w_o, bb_h_o, _, _, _ = Table[j]\n",
    "            \n",
    "            cost = calculate_cost(entry, Table[j])\n",
    "            #print('cost:', cost)\n",
    "            #cost = 10 if pid == pid_o else -1\n",
    "            \n",
    "            if abs(f_o - f) > dst_theta:\n",
    "                # lifted edge\n",
    "                lifted_edges.append((i,j,cost))\n",
    "            else:\n",
    "                # normal edge\n",
    "                edges.append((i,j,cost))\n",
    "            \n",
    "            ALL_EDGES.append((i, j, cost))\n",
    "                \n",
    "    edges = np.array(edges)\n",
    "    lifted_edges = np.array(lifted_edges)\n",
    "    ALL_EDGES = np.array(ALL_EDGES)\n",
    "    \n",
    "    print('Edges', edges.shape)\n",
    "    print('Lifted Edges', lifted_edges.shape)\n",
    "    \n",
    "    fmt = '%d %d %f'\n",
    "    \n",
    "    np.savetxt('edges.txt', edges, delimiter=';', fmt=fmt)\n",
    "    np.savetxt('lifted_edges.txt', lifted_edges, delimiter=';', fmt=fmt)\n",
    "    \n",
    "    with open('config.txt', 'w+') as f:\n",
    "        print(str(n), file=f)\n",
    "        \n",
    "    return ALL_EDGES\n",
    "    \n",
    "                \n",
    "print(D.shape)\n",
    "ALL_EDGES = calculate_adj_list(D)\n",
    "#print(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "from matplotlib.colors import get_named_colors_mapping\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ALL_COLORS = list(get_named_colors_mapping().keys())\n",
    "\n",
    "result = genfromtxt('build/result.txt', delimiter=' ', dtype='uint32')\n",
    "\n",
    "def extract_ids(result):\n",
    "    #TODO: make this stuff better..\n",
    "    \n",
    "    candidates = []\n",
    "    n = np.max(result[:,1])  # total number of nodes\n",
    "    \n",
    "    Nodes = [i for i in range(n+1)]\n",
    "    \n",
    "    \n",
    "    for i, j, edge in result:\n",
    "        assert(i < j)\n",
    "        has_edge = edge == 0\n",
    "        \n",
    "        if has_edge:\n",
    "            repres = Nodes[i]\n",
    "            Nodes[j] = repres\n",
    "\n",
    "    #print(Nodes)     \n",
    "    return Nodes\n",
    "            \n",
    "        \n",
    "\n",
    "Nodes = extract_ids(result)\n",
    "\n",
    "def get_bb(i, D):\n",
    "    left = D[i,2]\n",
    "    top = D[i,3]\n",
    "    width = D[i,4]\n",
    "    height = D[i,5]\n",
    "    return left, top, width, height\n",
    "\n",
    "def get_line(i, j, D):\n",
    "    x1,y1,w1,h1 = get_bb(i, D)\n",
    "    x2,y2,w2,h2 = get_bb(j, D)\n",
    "    \n",
    "    center = lambda x,y,w,h: (x+(w/2), y+(h/2))\n",
    "    \n",
    "    A = center(x1,y1,w1,h1)\n",
    "    B = center(x2,y2,w2,h2)\n",
    "    return [A[0], B[0]], [A[1], B[1]]\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(16,8))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.imshow(X[0])\n",
    "\n",
    "\n",
    "ALL_COLORS = ['red', 'green', 'blue', 'yellow', 'pink', 'purple', 'white', 'magenta']\n",
    "\n",
    "color_lookup = {}\n",
    "for i,N in enumerate(np.unique(Nodes)):\n",
    "    color_lookup[str(N)] = ALL_COLORS[i]\n",
    "\n",
    "for i, node in enumerate(Nodes):\n",
    "    l,t,w,h = get_bb(i, D)\n",
    "    bbX, bbY = utils.bb_to_plt_plot(l, t, w, h)\n",
    "    ax.plot(bbX, bbY, linewidth=1, color=color_lookup[str(Nodes[i])], alpha=0.5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "A = cv2.cvtColor(X[0], cv2.COLOR_RGB2GRAY)\n",
    "B = cv2.cvtColor(X[100], cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "flow = cv2.calcOpticalFlowFarneback(A, B, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "\n",
    "hsv = np.zeros_like(X[0])\n",
    "hsv[...,1] = 255\n",
    "mag, ang = cv2.cartToPolar(flow[...,0], flow[...,1])\n",
    "hsv[...,0] = ang*180/np.pi/2\n",
    "hsv[...,2] = cv2.normalize(mag,None,0,255,cv2.NORM_MINMAX)\n",
    "bgr = cv2.cvtColor(hsv,cv2.COLOR_HSV2RGB)\n",
    "print(np.max(bgr))\n",
    "\n",
    "fig = plt.figure(figsize=(16, 16))\n",
    "\n",
    "fig.add_subplot(311).imshow(X[0])\n",
    "fig.add_subplot(312).imshow(bgr)\n",
    "\n",
    "fig.add_subplot(313).imshow(X[5])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flow = cv2.optflow.createOptFlow_DeepFlow()\n",
    "\n",
    "A = cv2.cvtColor(X[0], cv2.COLOR_RGB2GRAY)\n",
    "B = cv2.cvtColor(X[100], cv2.COLOR_RGB2GRAY)\n",
    "C = None\n",
    "flow = flow.calc(A, B, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hsv = np.zeros_like(X[0])\n",
    "hsv[...,1] = 255\n",
    "mag, ang = cv2.cartToPolar(flow[...,0], flow[...,1])\n",
    "hsv[...,0] = ang*180/np.pi/2\n",
    "hsv[...,2] = cv2.normalize(mag,None,0,255,cv2.NORM_MINMAX)\n",
    "bgr = cv2.cvtColor(hsv,cv2.COLOR_HSV2RGB)\n",
    "print(np.max(bgr))\n",
    "\n",
    "fig = plt.figure(figsize=(16, 16))\n",
    "\n",
    "fig.add_subplot(311).imshow(X[0])\n",
    "fig.add_subplot(312).imshow(bgr)\n",
    "\n",
    "fig.add_subplot(313).imshow(X[5])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
